{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from skimage.color import lab2rgb, rgb2gray\n",
    "import torchvision.transforms as T\n",
    "from basic_model import ColorizationNet\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Read the two input parameters, which is the model checkpoint and grayscale image\n",
    "    model_checkpoint, gray_image = '.\\\\vae-best-model.pth', '.\\\\Places365_val_00000091.jpg'\n",
    "    # Load model from basic_model.py by calling the class constructor\n",
    "    model = ColorizationNet()\n",
    "    # If GPU available, set current execution to the CUDA instance, else, use CPU\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "        device = torch.device('cuda')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "\n",
    "    # Load checkpoint\n",
    "    checkpoint = torch.load(model_checkpoint)\n",
    "    model.load_state_dict(checkpoint, strict=False)\n",
    "\n",
    "    # Open the grayscale image\n",
    "    o = Image.open(gray_image)\n",
    "    image = Image.open(gray_image)\n",
    "    x = Image.open(gray_image).convert(\"L\")\n",
    "    arr = np.asarray(x)\n",
    "    gray = rgb2gray(np.array(image))\n",
    "    gray = T.ToTensor()(gray).float()\n",
    "    gray = T.Resize(size=(224, 224))(gray)\n",
    "    gray = gray.unsqueeze_(0)\n",
    "\n",
    "    # Evaluate the image from the model\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        preds = model(gray.to(device))\n",
    "\n",
    "    ab_output = preds[0].cpu()\n",
    "    color_image = torch.cat((gray[0], ab_output), 0).numpy()\n",
    "    color_image = color_image.transpose((1, 2, 0))\n",
    "    color_image[:, :, 0] = color_image[:, :, 0] * 100\n",
    "    color_image[:, :, 1:3] = color_image[:, :, 1:3] * 255 - 128\n",
    "    final = lab2rgb(color_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,3, figsize=(10, 10))\n",
    "axs[0].set_title('Grayscale Image')\n",
    "axs[0].imshow(arr, cmap='gray', vmin=0, vmax=255)\n",
    "axs[1].set_title('Colorized Image')\n",
    "axs[1].imshow(final)\n",
    "axs[2].set_title('Original Image')\n",
    "axs[2].imshow(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6e6013f052bd17526d25655e5a54fc0ac8f0a730f9cb4d33cf432e7185ecfd99"
  },
  "kernelspec": {
   "display_name": "Python 3.7.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
